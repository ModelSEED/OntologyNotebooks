{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure KBase Jupyter Dev Environment\n",
    "<sub><sup>(contact chenry@anl.gov with questions)</sub></sup>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "perl"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python version 3.9.13\n",
      "KBBaseModules 0.0.1\n",
      "Output files printed to:/Users/chenry/workspace/Notebooks//Ontology//sessions/default/output when using KBDevUtils.output_dir\n",
      "modelseedpy 0.3.3\n",
      "cobrakbase 0.3.1\n"
     ]
    }
   ],
   "source": [
    "%run annoontutil.py\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating TIGRFAM dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "perl"
    }
   },
   "outputs": [],
   "source": [
    "ontologyutil.build_tigrfam_dictionary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the annotation ontology API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "perl"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'installed_clients.GenomeFileUtilClient'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/ph/360gp1jx5zg7qyqv076prl240000gn/T/ipykernel_2769/2403892427.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0manno_api\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkbdevutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manno_client\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnative_python_api\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m output = anno_api.add_annotation_ontology_events({\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;34m\"input_ref\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"83333.1\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m#Name of your input object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m\"input_workspace\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"chenry:narrative_1591451745118\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m#Workspace with your input object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m\"output_name\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"83333.1.annotated\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m#Name to which the modified object should be saved\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code//cb_annotation_ontology_api/lib/cb_annotation_ontology_api/annotation_ontology_api.py\u001b[0m in \u001b[0;36madd_annotation_ontology_events\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[0;31m#Saving object if requested but not if it's an AMA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"save\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m             \u001b[0msave_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msave_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code//cb_annotation_ontology_api/lib/cb_annotation_ontology_api/annotation_ontology_api.py\u001b[0m in \u001b[0;36msave_object\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;31m#No specific instructions for handling these types yet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"KBaseGenomes.Genome\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"KBaseMetagenomes.AnnotatedMetagenomeAssembly\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m             \u001b[0msave_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_genome_or_metagenome\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"output_name\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"output_workspace\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"KBaseSequences.ProteinSequenceSet\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"KBaseSequences.DNASequenceSet\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code//KBBaseModules/kbbasemodules/basemodule.py\u001b[0m in \u001b[0;36msave_genome_or_metagenome\u001b[0;34m(self, objid, workspace, obj_json)\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_genome_or_metagenome\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mobjid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mworkspace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mobj_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ws\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworkspace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m         save_output = self.gfu_client().save_one_genome({\n\u001b[0m\u001b[1;32m    266\u001b[0m             \u001b[0;34m\"name\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mobjid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0;34m\"data\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mobj_json\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code//KBBaseModules/kbbasemodules/basemodule.py\u001b[0m in \u001b[0;36mgfu_client\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    113\u001b[0m                 \u001b[0;32mfrom\u001b[0m \u001b[0mkbbasemodules\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGenomeFileUtil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m                 \u001b[0;32mfrom\u001b[0m \u001b[0minstalled_clients\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGenomeFileUtilClient\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGenomeFileUtil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclients\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"GenomeFileUtil\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGenomeFileUtil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_url\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclients\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"GenomeFileUtil\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'installed_clients.GenomeFileUtilClient'"
     ]
    }
   ],
   "source": [
    "anno_api = kbdevutil.anno_client(native_python_api=True)\n",
    "output = anno_api.add_annotation_ontology_events({\n",
    "    \"input_ref\":\"83333.1\",#Name of your input object\n",
    "    \"input_workspace\":\"chenry:narrative_1591451745118\",#Workspace with your input object\n",
    "    \"output_name\":\"83333.1.annotated\",#Name to which the modified object should be saved\n",
    "    \"output_workspace\":\"chenry:narrative_1591451745118\",#Workspace where output should be saved\n",
    "    \"clear_existing\":0,#Set to 1 to clear existing annotations (don’t do this)\n",
    "    \"overwrite_matching\":1,#Overwrites annotations for matching event IDs\n",
    "    \"save\":1,#Set to one to save the output object\n",
    "    \"events\":[#Here you list all the annotation events you want to add to the object (you can add more than 1)\n",
    "        {\n",
    "            \"ontology_id\" : \"TIGR\",\n",
    "            \"description\" : \"TIGR annotations with sneckmer\",\n",
    "            \"method_version\" : \"1.0\",\n",
    "            \"method\" : \"sneckmer\",#Put the name of your sneckmer function here\n",
    "            \"timestamp\" : \"2020-12-29T19:32:45\",\n",
    "            \"ontology_terms\":{\"83333.1_64\" : [\n",
    "                 {\n",
    "                     \"term\" : \"TIGR00079\",\n",
    "                     \"evidence\" : {\"scores\":{\"probability\":0.67}}\n",
    "                 }\n",
    "              ]\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "perl"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "kbdevutil = KBDevUtils(\"Ontology\",ws_version=\"appdev\")\n",
    "appdev_annoapi = kbdevutil.anno_client(native_python_api=True)\n",
    "with open('debug.json') as json_file:\n",
    "    input_data = json.load(json_file)\n",
    "output = anno_api.add_annotation_ontology_events(input_data)\n",
    "output = anno_api.get_annotation_ontology_events({\n",
    "    \"input_ref\" : \"102004/Methanosarcina_acetivorans_C2A_DRAM_RAST\"\n",
    "#    \"input_ref\" : \"93487/Ruepo_2orMoreRKM\"\n",
    "#    \"input_ref\" : \"77537/Sco_RAST_Prokka_BlastKOALA_PTools_DeepEC_DeepGO\"\n",
    "#    \"input_ref\" : \"77537/Sco_Union_BestUnion_2plus_Best2plus_RASTKEGG\"\n",
    "#    \"input_ref\" : \"77925/Pf5.6\"#,\n",
    "#    \"input_workspace\" : \n",
    "})\n",
    "with open('output.json', 'w') as outfile:\n",
    "    json.dump(output, outfile, indent=2)\n",
    "\n",
    "terms = ontology[\"events\"][0][\"ontology_terms\"]\n",
    "ontology[\"events\"][0][\"ontology_id\"] = \"SEED\"\n",
    "for gene in terms:\n",
    "    terms[gene][0][\"evidence\"] = \"test\"\n",
    "    terms[gene][0][\"term\"] = terms[gene][0][\"term\"].split(\":\")[1]\n",
    "    \n",
    "output = anno_api.add_annotation_ontology_events({\n",
    "    \"input_ref\" : \"GCF_000012265.1\",\n",
    "    \"input_workspace\" : 77925,\n",
    "    \"output_name\" : \"TestOntologyOutput\",\n",
    "    \"events\" : ontology[\"events\"],\n",
    "    \"output_workspace\": \"kimbrel1:narrative_1606152384556\",\n",
    "    \"save\" : 1\n",
    "})\n",
    "\n",
    "ontology = anno_api.get_annotation_ontology_events({\n",
    "    \"input_ref\" : \"TestOntologyOutput\",\n",
    "    \"input_workspace\" : \"kimbrel1:narrative_1606152384556\"\n",
    "})\n",
    "\n",
    "with open('/Users/chenry/output.json', 'w') as outfile:\n",
    "    json.dump(ontology, outfile, indent=2)\n",
    "\n",
    "#Escherichia_coli_K-12_MG1655\n",
    "#Synechocystis_PCC_6803\n",
    "#Methanosarcina_barkeri_Fusaro\n",
    "#Clostridium_beijerinckii_NCIMB_8052\n",
    "#Streptomyces_coelicolor_A3_2\n",
    "\n",
    "ontology_input = {\n",
    "    \"input_ref\":\"Streptomyces_coelicolor_A3_2\",\n",
    "    \"input_workspace\":\"chenry:narrative_1612295985064\",\n",
    "    \"output_name\":\"test\",\n",
    "    \"output_workspace\":\"chenry:narrative_1612295985064\",\n",
    "    \"clear_existing\":0,\n",
    "    \"overwrite_matching\":1,\n",
    "    \"save\":1,\n",
    "    \"events\":[\n",
    "        {\n",
    "            \"event_id\": \"annotate_genome:1.8.1:SSO:2020-11-23T17:51:18\",\n",
    "            \"original_description\": \"annotate_genome:2020-11-23T17:51:18:2020-11-23T17:51:18\",\n",
    "            \"description\": \"annotate_genome:2020-11-23T17:51:18:2020-11-23T17:51:18:2020-11-23T17:51:18\",\n",
    "            \"ontology_id\": \"SSO\",\n",
    "            \"method\": \"annotate_genome\",\n",
    "            \"method_version\": \"1.8.1\",\n",
    "            \"timestamp\": \"2020-11-23T17:51:18\",\n",
    "            \"ontology_terms\":{\"sgl0001\": [{\"term\": \"SSO:000001563\"}]}\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "#with open('/Users/chenry/ontology_api_input.json') as json_file:\n",
    "#    ontology_input = json.load(json_file)\n",
    "#print(\"Loading ontology terms to genome!\")\n",
    "output = anno_api.add_annotation_ontology_events(ontology_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Published Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "perl"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import cobra\n",
    "import cobrakbase\n",
    "kbase_api = cobrakbase.KBaseAPI()\n",
    "\n",
    "genome_list = [\"Sco\",\"Eco\",\"Cbe\",\"Mba\"]\n",
    "pub_model_hash = {\n",
    "    \"Sco\" : \"iMK1208\",\n",
    "    \"Eco\" : \"iML1515.kb\",\n",
    "    \"Cbe\" : \"iCM925_GF\",\n",
    "    \"Mba\" : \"iMG746_GF\"\n",
    "}\n",
    "pub_fba_hash = {\n",
    "    \"Sco\" : \"iMK1208_FBA\",\n",
    "    \"Eco\" : \"iML1515.kb_FBA\",\n",
    "    \"Cbe\" : \"iCM925_FBA\",\n",
    "    \"Mba\" : \"iMG746_FBA\"\n",
    "}\n",
    "pub_pheno_hash = {\n",
    "    \"Sco\" : \"iMK1208_Pheno\",\n",
    "    \"Eco\" : \"iML1515.kb_Pheno\",\n",
    "    \"Cbe\" : \"iCM925_Pheno\",\n",
    "    \"Mba\" : \"iMG746_Pheno\"\n",
    "}\n",
    "stats = {\n",
    "    \"Sco\":{},\"Eco\":{},\"Cbe\":{},\"Mba\":{}\n",
    "}\n",
    "types = [\"Best\",\"Union\",\"RAST\",\"Published\"]\n",
    "entities = [\"gene\",\"reaction\",\"pospheno\"]\n",
    "print(\"Species\\tType\\tReactions\\tGenes\\tGapfilled\\tBlocked\\tPospheno\\tGene match\\tReaction match\\tPheno match\")\n",
    "for genome in genome_list:\n",
    "    #Get:gene associated reactions;genes;gapfilled\n",
    "    models = [genome+\"_Best\",genome+\"_Union\",genome+\"_StdRAST_Mdl\",pub_model_hash[genome]]\n",
    "    count = 0\n",
    "    for model in models:\n",
    "        current_object = kbase_api.get_object(model,\"patrikd:narrative_1605639637696\")\n",
    "        stats[genome][types[count]] = {\n",
    "            \"reactions\":0,\n",
    "            \"gapfilled\":0,\n",
    "            \"blocked\":0,\n",
    "            \"genes\":0,\n",
    "            \"gene_hash\":{},\n",
    "            \"reaction_hash\":{},\n",
    "            \"pospheno\":0,\n",
    "            \"pospheno_hash\":{},\n",
    "            \"match_reaction\":0,\n",
    "            \"match_gene\":0,\n",
    "            \"match_pospheno\":0\n",
    "        }\n",
    "        for rxn in current_object[\"modelreactions\"]:\n",
    "            rxn[\"id\"] = rxn[\"id\"].replace(\"_z0\",\"_c0\")\n",
    "            if \"gapfill_data\" in rxn and len(rxn[\"gapfill_data\"]) > 0:\n",
    "                stats[genome][types[count]][\"gapfilled\"] += 1\n",
    "            elif count == 3 and len(rxn[\"modelReactionProteins\"]) == 0:\n",
    "                stats[genome][types[count]][\"gapfilled\"] += 1\n",
    "            if len(rxn[\"modelReactionProteins\"]) > 0:\n",
    "                stats[genome][types[count]][\"reactions\"] += 1\n",
    "                stats[genome][types[count]][\"reaction_hash\"][rxn[\"id\"]] = 1\n",
    "                for prot in rxn[\"modelReactionProteins\"]:\n",
    "                    for subunit in prot[\"modelReactionProteinSubunits\"]:\n",
    "                        for ftr in subunit[\"feature_refs\"]:\n",
    "                            ftr = ftr.split(\"/\").pop()\n",
    "                            stats[genome][types[count]][\"gene_hash\"][ftr] = 1             \n",
    "        stats[genome][types[count]][\"genes\"] = len(stats[genome][types[count]][\"gene_hash\"])\n",
    "        count += 1\n",
    "    \n",
    "    #Get:blocked\n",
    "    models = [genome+\"_Best_FBA\",genome+\"_Union_FBA\",genome+\"_StdRAST_FBA\",pub_fba_hash[genome]]\n",
    "    count = 0\n",
    "    for model in models:\n",
    "        current_object = kbase_api.get_object(model,\"patrikd:narrative_1605639637696\")\n",
    "        for var in current_object[\"FBAReactionVariables\"]:\n",
    "            if var[\"class\"] == \"Blocked\":\n",
    "                stats[genome][types[count]][\"blocked\"] += 1\n",
    "        count += 1\n",
    "    #Get:Neg;Pos\n",
    "    models = [genome+\"_Best_Pheno\",genome+\"_Union_Pheno\",genome+\"_StdRAST_Pheno\",pub_pheno_hash[genome]]\n",
    "    count = 0\n",
    "    for model in models:\n",
    "        if not (count == 3 and genome == \"Sco\"):\n",
    "            current_object = kbase_api.get_object(model,\"patrikd:narrative_1605639637696\")\n",
    "            for pheno in current_object[\"phenotypeSimulations\"]:\n",
    "                if pheno[\"simulatedGrowth\"] > 0:\n",
    "                    stats[genome][types[count]][\"pospheno_hash\"][pheno[\"id\"]] = 1\n",
    "                    stats[genome][types[count]][\"pospheno\"] += 1\n",
    "        count += 1   \n",
    "    #Computing matches\n",
    "    for entity in entities:\n",
    "        for count in range(0,3):\n",
    "            for entid in stats[genome][\"Published\"][entity+\"_hash\"]:\n",
    "                if entid in stats[genome][types[count]][entity+\"_hash\"]:\n",
    "                    stats[genome][types[count]][\"match_\"+entity] += 1\n",
    "    #Printing results\n",
    "    for currtype in types:\n",
    "        d = stats[genome][currtype]\n",
    "        print(genome+\"\\t\"+currtype+\"\\t\"+str(d[\"reactions\"])+\"\\t\"+str(d[\"genes\"])+\"\\t\"+str(d[\"gapfilled\"])\\\n",
    "            +\"\\t\"+str(d[\"blocked\"])+\"\\t\"+str(d[\"pospheno\"])+\"\\t\"+str(d[\"match_gene\"])+\"\\t\"+str(d[\"match_reaction\"])+\"\\t\"+str(d[\"match_pospheno\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Ontology API Against Gold Standard Genomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "perl"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import cobra\n",
    "import cobrakbase\n",
    "sys.path.append(\"/Users/chenry/code/MetabolicModelGapfilling/lib/\")\n",
    "#sys.path.append(\"/Users/chenry/code/annotation_ontology_api/lib\")\n",
    "from annotation_ontology_api.annotation_ontology_apiServiceClient import annotation_ontology_api\n",
    "#from annotation_ontology_api.annotation_ontology_api import AnnotationOntologyAPI\n",
    "\n",
    "#Test for ontology API\n",
    "kbase_api = cobrakbase.KBaseAPI()\n",
    "#anno_api = AnnotationOntologyAPI({\"data_directory\" : \"/Users/chenry/code/annotation_ontology_api/data/\"},kbase_api.ws_client,None)\n",
    "anno_api = annotation_ontology_api()\n",
    "genome_list = [\"Ani_RAST\"]\n",
    "#genome_list = [\"Sco_RAST\",\"Eco_RAST\",\"Cbe_RAST\",\"Syn_RAST\",\"Mba_RAST\"]\n",
    "genome_hash = {\n",
    "    \"Eco_RAST\": \"Eco_RAST_Prokka\",\n",
    "    \"Cbe_RAST\": \"Cbe_RAST_Prokka\",\n",
    "    \"Syn_RAST\": \"Syn_RAST_Prokka\",\n",
    "    \"Mba_RAST\": \"Mba_RAST_Prokka\",\n",
    "    \"Sco_RAST\": \"Sco_RAST_Prokka_BlastKOALA_PTools_DeepEC_DeepGO\",\n",
    "    \"Ani_RAST\": \"Ani_RAST_Prokka\"\n",
    "}\n",
    "for genome in genome_list:\n",
    "    print(genome)\n",
    "    ontology_output = anno_api.get_annotation_ontology_events({\n",
    "        \"input_ref\" : \"patrikd:narrative_1605639637696/\"+genome,\n",
    "    })\n",
    "    genome_object = kbase_api.get_object(genome,\"patrikd:narrative_1605639637696\")\n",
    "    ontology_input = {\n",
    "        \"input_ref\":genome_hash[genome],\n",
    "        \"input_workspace\":\"patrikd:narrative_1605639637696\",\n",
    "        \"output_name\":genome_hash[genome],\n",
    "        \"output_workspace\":\"patrikd:narrative_1605639637696\",        \n",
    "        \"save\":1,\n",
    "#        \"type\":\"KBaseGenomes.Genome\",\n",
    "#        \"object\":genome,\n",
    "        \"clear_existing\":0,\n",
    "        \"overwrite_matching\":1,\n",
    "        \"events\":[]\n",
    "    }\n",
    "    for event in ontology_output[\"events\"]:\n",
    "        print(event[\"ontology_id\"])\n",
    "        if event[\"ontology_id\"] == \"SSO\":\n",
    "            ontology_input[\"events\"].append(event)\n",
    "            break\n",
    "    \n",
    "    with open('/Users/chenry/output.json', 'w') as outfile:\n",
    "        json.dump(ontology_output, outfile, indent=2)\n",
    "    \n",
    "    if len(ontology_input[\"events\"]) == 1:\n",
    "        print(str(len(ontology_input[\"events\"])))\n",
    "        print(ontology_input[\"events\"][0][\"ontology_id\"])\n",
    "        ontology_output[\"events\"][0][\"method\"] = \"RAST annotation\"\n",
    "        ontology_output[\"events\"][0][\"description\"] = \"RAST annotation:\"+ontology_output[\"events\"][0][\"ontology_id\"]+\":\"+ontology_output[\"events\"][0][\"timestamp\"]    \n",
    "        ontology_output[\"events\"][0][\"ontology_terms\"] = {}\n",
    "        for ftr in genome_object[\"features\"]:\n",
    "            if \"functions\" in ftr:\n",
    "                for func in ftr[\"functions\"]:\n",
    "                    if ftr[\"id\"] not in ontology_input[\"events\"][0][\"ontology_terms\"]:\n",
    "                        ontology_input[\"events\"][0][\"ontology_terms\"][ftr[\"id\"]] = []\n",
    "                    ontology_input[\"events\"][0][\"ontology_terms\"][ftr[\"id\"]].append({\n",
    "                        \"term\": \"SSO:\"+func\n",
    "                    })\n",
    "        for ftr in genome_object[\"cdss\"]:\n",
    "            if \"functions\" in ftr:\n",
    "                for func in ftr[\"functions\"]:\n",
    "                    if ftr[\"id\"] not in ontology_input[\"events\"][0][\"ontology_terms\"]:\n",
    "                        ontology_input[\"events\"][0][\"ontology_terms\"][ftr[\"id\"]] = []\n",
    "                    ontology_input[\"events\"][0][\"ontology_terms\"][ftr[\"id\"]].append({\n",
    "                        \"term\": \"SSO:\"+func\n",
    "                    })\n",
    "        ontology_output = anno_api.add_annotation_ontology_events(ontology_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Printing SSO reactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Printing Super Annotated E. coli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "perl"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/Users/chenry/code/cb_annotation_ontology_api/lib\")\n",
    "import os\n",
    "import cobra\n",
    "import cobrakbase\n",
    "import json\n",
    "import csv\n",
    "import logging\n",
    "import cplex\n",
    "import optlang\n",
    "import re\n",
    "import pandas as pd\n",
    "from optlang.symbolics import Zero, add\n",
    "import cobra.util.solver as sutil\n",
    "from cobrakbase.core.converters import KBaseFBAModelToCobraBuilder\n",
    "from cobrakbase.Workspace.WorkspaceClient import Workspace as WorkspaceClient\n",
    "from annotation_ontology_api.annotation_ontology_api import AnnotationOntologyAPI\n",
    "from cobra.core.dictlist import DictList\n",
    "from cobra.core import Gene, Metabolite, Model, Reaction\n",
    "from IPython.core.display import HTML\n",
    "#Test for ontology API\n",
    "kbase_api = cobrakbase.KBaseAPI()\n",
    "anno_api = AnnotationOntologyAPI({\"data_directory\" : \"/Users/chenry/code/cb_annotation_ontology_api/data/\"},\n",
    "    kbase_api.ws_client,None)\n",
    "\n",
    "output = anno_api.get_annotation_ontology_events({\n",
    "    \"input_ref\" : \"Eco_Union_BestUnion_2plus_Best2plus_RASTKEGG.pdb\",\n",
    "    \"input_workspace\" : 133085\n",
    "})\n",
    "with open('EcoliSuperAnnotation', 'w') as outfile:\n",
    "    json.dump(output, outfile, indent=2)\n",
    "#Print annotations in tabular form\n",
    "annotations = {}\n",
    "for event in output[\"events\"]:\n",
    "    name = None\n",
    "    if event[\"original_description\"][0:4] == \"RAST\":\n",
    "        name = \"RAST\"\n",
    "    elif event[\"original_description\"][0:6] == \"Prokka\":\n",
    "        name = \"Prokka\"\n",
    "    elif event[\"original_description\"][0:5] == \"Blast\":\n",
    "        name = \"Koala\"\n",
    "    elif event[\"original_description\"][0:7] == \"Pathway\":\n",
    "        name = \"PathwayTools\"\n",
    "    elif event[\"original_description\"][0:6] == \"DeepEC\":\n",
    "        name = \"DeepEC\"\n",
    "    elif event[\"original_description\"][0:6] == \"DeepGO\":\n",
    "        name = \"DeepGO\"\n",
    "    elif event[\"original_description\"][0:3] == \"KBA\":\n",
    "        name = \"PDB\"\n",
    "    if name:\n",
    "        for gene in event[\"ontology_terms\"]:\n",
    "            for item in event[\"ontology_terms\"][gene]:\n",
    "                if \"modelseed_ids\" in item:\n",
    "                    if gene not in annotations:\n",
    "                        annotations[gene] = {}\n",
    "                    for msid in item[\"modelseed_ids\"]:\n",
    "                        if msid not in annotations[gene]:\n",
    "                            annotations[gene][msid] = {}\n",
    "                        if name not in annotations[gene][msid]:\n",
    "                            annotations[gene][msid][name] = []\n",
    "                        if item[\"term\"] not in annotations[gene][msid][name]:\n",
    "                            annotations[gene][msid][name].append(item[\"term\"])\n",
    "#Loading and saving dataframe\n",
    "annos = [\"RAST\",\"Prokka\",\"Koala\",\"PathwayTools\",\"DeepEC\",\"DeepGO\",\"PDB\"]\n",
    "data = {\"Gene\":[],\"Reactions\":[],\"RAST\":[],\"Prokka\":[],\"Koala\":[],\"PathwayTools\":[],\"DeepEC\":[],\"DeepGO\":[],\"PDB\":[]}\n",
    "for gene in annotations:\n",
    "    for rxn in annotations[gene]:\n",
    "        data[\"Gene\"].append(gene)\n",
    "        data[\"Reactions\"].append(rxn)\n",
    "        for anno in annos:\n",
    "            if anno in annotations[gene][rxn]:\n",
    "                data[anno].append(\",\".join(annotations[gene][rxn][anno]))\n",
    "            else:\n",
    "                data[anno].append(None)\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(\"EcoliSuperAnnotated.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "vscode": {
     "languageId": "perl"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'anno_api' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/chenry/code/ProjectNotebooks/TemplateFunctions/OntologyFunctions.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/chenry/code/ProjectNotebooks/TemplateFunctions/OntologyFunctions.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m ontology \u001b[39m=\u001b[39m anno_api\u001b[39m.\u001b[39mget_annotation_ontology_events({\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/chenry/code/ProjectNotebooks/TemplateFunctions/OntologyFunctions.ipynb#X22sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39minput_ref\u001b[39m\u001b[39m\"\u001b[39m : \u001b[39m\"\u001b[39m\u001b[39mPf5.6\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/chenry/code/ProjectNotebooks/TemplateFunctions/OntologyFunctions.ipynb#X22sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39minput_workspace\u001b[39m\u001b[39m\"\u001b[39m : \u001b[39m77925\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/chenry/code/ProjectNotebooks/TemplateFunctions/OntologyFunctions.ipynb#X22sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m })\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/chenry/code/ProjectNotebooks/TemplateFunctions/OntologyFunctions.ipynb#X22sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m/Users/chenry/translation.json\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m outfile:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/chenry/code/ProjectNotebooks/TemplateFunctions/OntologyFunctions.ipynb#X22sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     json\u001b[39m.\u001b[39mdump(anno_api\u001b[39m.\u001b[39malias_hash, outfile, indent\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'anno_api' is not defined"
     ]
    }
   ],
   "source": [
    "ontology = anno_api.get_annotation_ontology_events({\n",
    "    \"input_ref\" : \"Pf5.6\",\n",
    "    \"input_workspace\" : 77925\n",
    "})\n",
    "with open('/Users/chenry/translation.json', 'w') as outfile:\n",
    "    json.dump(anno_api.alias_hash, outfile, indent=2)\n",
    "with open('/Users/chenry/output.json', 'w') as outfile:\n",
    "    json.dump(ontology, outfile, indent=2)\n",
    "\n",
    "terms = ontology[\"events\"][0][\"ontology_terms\"]\n",
    "ontology[\"events\"][0][\"ontology_id\"] = \"SEED\"\n",
    "for gene in terms:\n",
    "    terms[gene][0][\"evidence\"] = \"test\"\n",
    "    terms[gene][0][\"term\"] = terms[gene][0][\"term\"].split(\":\")[1]\n",
    "    \n",
    "with open('/Users/chenry/output2.json', 'w') as outfile:\n",
    "    json.dump(ontology, outfile, indent=2)\n",
    "    \n",
    "output = anno_api.add_annotation_ontology_events({\n",
    "    \"input_ref\" : \"GCF_000012265.1\",\n",
    "    \"input_workspace\" : 77925,\n",
    "    \"output_name\" : \"TestOntologyOutput\",\n",
    "    \"events\" : ontology[\"events\"],\n",
    "    \"output_workspace\": \"kimbrel1:narrative_1606152384556\",\n",
    "    \"save\" : 1\n",
    "})\n",
    "\n",
    "#with open('/Users/chenry/genome.json', 'w') as outfile:\n",
    "#    json.dump(output[\"object\"], outfile, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Not sure what this code is doing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "vscode": {
     "languageId": "perl"
    }
   },
   "outputs": [],
   "source": [
    "sso_hash = dict()\n",
    "with open('/Users/chenry/Dropbox/workspace/KBase Project/TemplateFunctions/genome_sso.json') as json_file:\n",
    "    sso_hash = json.load(json_file)\n",
    "\n",
    "sso_template = dict()\n",
    "with open('/Users/chenry/Dropbox/workspace/KBase Project/TemplateFunctions/SSO_reactions.json') as json_file:\n",
    "    sso_template = json.load(json_file)\n",
    "\n",
    "reaction_hash = dict()\n",
    "with open('/Users/chenry/Dropbox/workspace/KBase Project/TemplateFunctions/genome_reactions.json') as json_file:\n",
    "    reaction_hash = json.load(json_file)\n",
    "\n",
    "function_hash = dict()\n",
    "with open('/Users/chenry/Dropbox/workspace/KBase Project/TemplateFunctions/genome_functions.json') as json_file:\n",
    "    function_hash = json.load(json_file)\n",
    "\n",
    "functions = dict()\n",
    "comparison = dict()\n",
    "for genome in sso_hash:\n",
    "    if genome in reaction_hash:\n",
    "        sso_based_reactions = dict()\n",
    "        sso_based_genes = dict()\n",
    "        for gene in sso_hash[genome]:\n",
    "            for sso in sso_hash[genome][gene]:\n",
    "                if sso in sso_template:\n",
    "                    for reaction in sso_template[sso]:\n",
    "                        if reaction not in sso_based_reactions:\n",
    "                            sso_based_reactions[reaction] = dict()\n",
    "                        sso_based_reactions[reaction][gene] = 1\n",
    "                        if gene not in sso_based_genes:\n",
    "                            sso_based_genes[gene] = dict()\n",
    "                        sso_based_genes[gene][reaction] = 1\n",
    "        comparison[genome] = {\n",
    "            \"SSO_reactions\": len(sso_based_reactions),\n",
    "            \"SSO_genes\": len(sso_based_genes),\n",
    "            \"Extra_SS_reactions\": [],\n",
    "            \"Extra_SS_genes\": [],\n",
    "            \"Extra_MS_reactions\": [],\n",
    "            \"Extra_MS_genes\": [],\n",
    "            \"Extra_SS_reactions_counts\": 0,\n",
    "            \"Extra_SS_genes_counts\": 0,\n",
    "            \"Extra_MS_reactions_counts\": 0,\n",
    "            \"Extra_MS_genes_counts\": 0,\n",
    "            \"MS_reactions\": len(reaction_hash[genome]),\n",
    "            \"MS_genes\" 0,\n",
    "        }\n",
    "        ms_based_genes = dict()\n",
    "        for reaction in reaction_hash[genome]:\n",
    "            if reaction not in sso_based_reactions:\n",
    "                comparison[genome][\"Extra_MS_reactions\"].append(reaction)\n",
    "                comparison[genome][\"Extra_MS_reactions_counts\"] += 1\n",
    "            for gene in reaction_hash[genome][reaction]:\n",
    "                if gene not in ms_based_genes:\n",
    "                    ms_based_genes[gene] = dict()\n",
    "                ms_based_genes[gene][reaction] = 1\n",
    "        for reaction in sso_based_reactions:\n",
    "            if reaction not in reaction_hash[genome]:\n",
    "                comparison[genome][\"Extra_SS_reactions\"].append(reaction)\n",
    "                comparison[genome][\"Extra_SS_reactions_counts\"] += 1\n",
    "        comparison[genome][\"MS_genes\"] = len(ms_based_genes)\n",
    "        for gene in ms_based_genes:\n",
    "            if gene not in sso_based_genes:\n",
    "                comparison[genome][\"Extra_MS_genes\"].append(gene)\n",
    "                comparison[genome][\"Extra_MS_genes_counts\"] += 1\n",
    "        for gene in sso_based_genes:\n",
    "            if gene not in ms_based_genes:\n",
    "                comparison[genome][\"Extra_SS_genes\"].append(gene)\n",
    "                comparison[genome][\"Extra_SS_genes_counts\"] += 1\n",
    "            \n",
    "with open('/Users/chenry/Dropbox/workspace/KBase Project/TemplateFunctions/comparison.json', 'w') as outfile:\n",
    "    json.dump(comparison, outfile)\n",
    "    \n",
    "with open('/Users/chenry/Dropbox/workspace/KBase Project/TemplateFunctions/problem_functions.json', 'w') as outfile:\n",
    "    json.dump(functions, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing reaction gene associations from all models in workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "perl"
    }
   },
   "outputs": [],
   "source": [
    "objects = msrecon.kbase_api.list_objects(\"chenry:narrative_1581959452634\")\n",
    "reaction_hash = dict()\n",
    "count = 0\n",
    "for obj in objects:\n",
    "    if obj[1][-14:] == \".RAST.mdl.base\":\n",
    "        count += 1\n",
    "        genomeid = obj[1][0:-14]\n",
    "        reaction_hash[genomeid] = dict()\n",
    "        model = kbase.get_from_ws(obj[1],\"chenry:narrative_1581959452634\")\n",
    "        for rxn in model.reactions:\n",
    "            reaction_hash[genomeid][rxn.id.split(\"_\")[0]] = dict()\n",
    "            for prot in rxn.data[\"modelReactionProteins\"]:\n",
    "                for subunit in prot[\"modelReactionProteinSubunits\"]:\n",
    "                    for ftr in subunit[\"feature_refs\"]:\n",
    "                        ftrid = ftr.split(\"/\").pop()\n",
    "                        reaction_hash[genomeid][rxn.id.split(\"_\")[0]][ftrid] = 0\n",
    "\n",
    "with open(kbdevutil.out_dir()+\"genome_reactions.json\", 'w') as outfile:\n",
    "    json.dump(reaction_hash, outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
